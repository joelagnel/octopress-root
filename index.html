
<!DOCTYPE html>
<!--[if IEMobile 7 ]><html class="no-js iem7"><![endif]-->
<!--[if lt IE 9]><html class="no-js lte-ie8"><![endif]-->
<!--[if (gt IE 8)|(gt IEMobile 7)|!(IEMobile)|!(IE)]><!--><html class="no-js" lang="en"><!--<![endif]-->
<head>
  <meta charset="utf-8">
  <title>Linux scratchpad</title>
  <meta name="author" content="Joel Fernandes">

  
  <meta name="description" content="Having read the chapter on counting and per-CPU counters in Paul Mckenney&rsquo;s recent book, I thought I would do a small experiment to check how &hellip;">
  

  <!-- http://t.co/dKP3o1e -->
  <meta name="HandheldFriendly" content="True">
  <meta name="MobileOptimized" content="320">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  
  <link rel="canonical" href="http://joelagnel.github.io">
  <link href="/favicon.png" rel="icon">
  <link href="/stylesheets/screen.css" media="screen, projection" rel="stylesheet" type="text/css">
  <link href="/atom.xml" rel="alternate" title="Linux scratchpad" type="application/atom+xml">
  <script src="/javascripts/modernizr-2.0.js"></script>
  <script src="//ajax.googleapis.com/ajax/libs/jquery/1.9.1/jquery.min.js"></script>
  <script>!window.jQuery && document.write(unescape('%3Cscript src="./javascripts/libs/jquery.min.js"%3E%3C/script%3E'))</script>
  <script src="/javascripts/octopress.js" type="text/javascript"></script>
  <!--Fonts from Google"s Web font directory at http://google.com/webfonts -->
<link href="//fonts.googleapis.com/css?family=PT+Serif:regular,italic,bold,bolditalic" rel="stylesheet" type="text/css">
<link href="//fonts.googleapis.com/css?family=PT+Sans:regular,italic,bold,bolditalic" rel="stylesheet" type="text/css">

  

</head>

<body   >
  <header role="banner"><hgroup>
  <h1><a href="/">Linux scratchpad</a></h1>
  
    <h2>Joel Fernandes' notes on Linux, embedded, architecture and algorithms.</h2>
  
</hgroup>

</header>
  <nav role="navigation"><ul class="subscription" data-subscription="rss">
  <li><a href="/atom.xml" rel="subscribe-rss" title="subscribe via RSS">RSS</a></li>
  
</ul>
  
<form action="https://www.google.com/search" method="get">
  <fieldset role="search">
    <input type="hidden" name="q" value="site:joelagnel.github.io" />
    <input class="search" type="text" name="q" results="0" placeholder="Search"/>
  </fieldset>
</form>
  
<ul class="main-navigation">
  <li><a href="/">Blog</a></li>
  <li><a href="/blog/archives">Archives</a></li>
</ul>

</nav>
  <div id="main">
    <div id="content">
      <div class="blog-index">
  
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2014/04/24/studying-cache-line-sharing-effects-on-smp-systems/">Studying Cache-line Sharing Effects on SMP Systems</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2014-04-24T20:28:24-05:00" pubdate data-updated="true">Apr 24<span>th</span>, 2014</time>
        
      </p>
    
  </header>


  <div class="entry-content"><p>Having read the chapter on counting and per-CPU counters in <a href="http://www.lulu.com/shop/paul-e-mckenney/is-parallel-programming-hard-and-if-so-what-can-you-do-about-it-first-bw-print-edition/paperback/product-21562459.html">Paul Mckenney&rsquo;s recent book</a>, I thought I would do a small experiment to check how good or bad it would be if those per-CPU counters were close to each other in memory.</p>

<p>Paul talks about using one global shared counter for N threads on N CPUs, and the effects it can have on the cache. Each CPU core&rsquo;s cache in an SMP system will need exclusive rights on a specific cache line of memory, before it can do the write. This means that, at any given time <em>only one</em> CPU can and should do a write to that part of memory.</p>

<p>This is accomplished typically by an invalidate protocol, where each CPU needs to do some inter-processor communication before it can assume it has exclusive access to that cache line, and also read any copies that may still be in some other core&rsquo;s cache and not in main memory. This is an expensive operation that is to be avoided at all costs!</p>

<p>Then Paul goes about saying, OK- let&rsquo;s have a per-thread counter, and have each core increment it independently, and when we need a read out, we would grab a lock and add all of the individual counters together. This works great, assuming each per-thread counter is separated by atleast a cache line. That&rsquo;s guaranteed, when one uses the __thread primitive nicely separating out the memory to reduce cache line sharing effects.</p>

<p>So I decided to flip this around, and have per-thread counters that were closely spaced and do some counting with them. Instead of using __thread, I created an array of counters, each element belonging to some thread. The counters are still separate and not shared, but they may still be in shared cache-line causing the nasty effects we talked about, which I wanted to measure.</p>

<p><a href="https://github.com/joelagnel/smp-experiments/blob/05afb2db4fea1c6c0b4614c180186c10627a341a/cache-sharing.c">My program</a> sets up N counting threads, and assumes its running each of them on a single core on typical multicore system.  Various iterations of per-thread counting is done, with the counters separated by increasing powers of 2 each iteration. After each iteration, I stop all threads, add the per-thread counter values and report the result.</p>

<p>Below are the results of running the program on 3 different SMP systems (2 threads on 2 CPUs, sorry I don&rsquo;t have better multi-core hardware ATM):</p>

<p>Effect of running on a reference ARM Dual-core Cortex-A9 system:
<img src="/images/cache-sharing/a9-counts.jpeg"></p>

<p>Notice the jump in through-put once the separation changes from 16 to 32 bytes. That gives us a good idea that the L1 cache line size on Cortex-A9 systems is 32 bytes (8 words). Something the author didn&rsquo;t know for sure in advance (I initially thought it was 64-bytes).</p>

<p>Effect of running on a reference ARM dual-core Cortex-A15 system:
<img src="/images/cache-sharing/a15-counts.jpeg"></p>

<p>L1 Cache-line size of Cortex A-15 is 64 bytes (8 words). Expected jump for a separation of 64 bytes.</p>

<p>Effect of running on a x86-64 i7-3687U Dual core CPU:
<img src="/images/cache-sharing/x86-counts.jpeg">.</p>

<p>L1 Cache-line size of this CPU is 64 bytes too (8 words). Expected jump for a separation of 64 bytes.</p>

<p>This shows your parallel programs need to take care of cache-line alignment to avoid false-sharing effects. Also, doing something like this in your program is an indirect way to find out what the cache-line size is for your CPU, or a direct way to get fired, whichever way you want to look at it. ;)</p>
</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2014/04/22/design-of-fork-followed-by-exec-in-linux/">Design of Fork Followed by Exec in Linux</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2014-04-22T23:06:11-05:00" pubdate data-updated="true">Apr 22<span>nd</span>, 2014</time>
        
      </p>
    
  </header>


  <div class="entry-content"><p>A popular topic among new Linux programmers is <em>why do you have to do fork and then an exec, to execute a new program?</em> and <em>why can&rsquo;t it be done in one step?</em> or <em>why does fork <a href="http://man7.org/linux/man-pages/man2/fork.2.html">create a copy-on-writed address space</a>, to only have it thrown away later when you do an exec?</em> So I decided do a small write up about this topic, also as a way to teach myself.</p>

<p>On a separate note, firstly it is important to remember that <code>fork</code> is not used for threading, its primary use is to create a separate process, that is a child of the one that called <code>fork</code>.</p>

<p>Normally one might think that doing a <code>fork</code> and <code>exec</code> calls can be combined in one step, and it probably should be. But there are applications of maintaining this separation. Here&rsquo;s a <a href="http://stackoverflow.com/questions/1345320/applications-of-fork-system-call">post that explains</a> why you might need to do just a <code>fork</code> call. Summarizing the post, you may need to setup some initial data and &ldquo;fork&rdquo; a bunch of workers. All these works are supposed to execute in <em>their own</em> address space and share <em>only the initial data</em>. In this case, copy-on-write is extremely useful since the initial data can be shared in physical memory and forking would be extremely. The kernel marks all these shared pages as read only, and makes writable copies on writes.</p>

<p>There is a small overhead if <code>fork</code> is followed immediately by an <code>exec</code> system call, since the copy-on-write shared address space is of no use and is thrown away. Combining both <code>fork</code>, <code>exec</code> in this case might might have some advantages, reducing this overhead.</p>

<p>Linux Implementation of Copy-on-write for shared Virtual Memory Areas
Some of this COW code that executes on a fork can be found in <code>mm/memory.c</code>. There is an is_cow function to detect if a virtual memory area (a region of virtual memory, see <code>/proc/self/maps</code>) is copy-on-write.</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
</pre></td><td class='code'><pre><code class='c'><span class='line'><span class="k">static</span> <span class="kr">inline</span> <span class="n">bool</span> <span class="nf">is_cow_mapping</span><span class="p">(</span><span class="n">vm_flags_t</span> <span class="n">flags</span><span class="p">)</span>
</span><span class='line'><span class="p">{</span>
</span><span class='line'>        <span class="k">return</span> <span class="p">(</span><span class="n">flags</span> <span class="o">&amp;</span> <span class="p">(</span><span class="n">VM_SHARED</span> <span class="o">|</span> <span class="n">VM_MAYWRITE</span><span class="p">))</span> <span class="o">==</span> <span class="n">VM_MAYWRITE</span><span class="p">;</span>
</span><span class='line'><span class="p">}</span>
</span></code></pre></td></tr></table></div></figure>


<p>Every VMA has a bunch of VM_ flags associated with it. <code>VM_MAYWRITE</code>, relevant to the above code, is used to mark that a mapped region can be changed to writable by mprotect system call. It is possible that a memory region is initially readonly and the user wants to make it writable. <code>VM_MAYWRITE</code> gives that permission. Note that if if the kernel doesn&rsquo;t set <code>VM_MAYWRITE</code>, then the region is automatically not COW because there is no question of writing to it.</p>

<p>When a memory mapping is created via the mmap system call, and if <code>MAP_SHARED</code> is passed in flags, the <code>VM_SHARED</code> bit is set and as a result the region is not copy-on-write. By definition, shared memory regions are just that &ndash; shared. So no need copy-on-write.</p>

<p>Let&rsquo;s take the example of mapping a file using mmap,</p>

<p>By default in the kernel on VMA creation, the VMA flags is set to <code>VM_SHARED = 0</code> and <code>VM_MAYWRITE = 1</code>. Now if mmap is asked it to create a shared mapping of a file by passing it <code>MAP_SHARED</code> flag, for example, that can be shared with other processes that are being forked, then the <code>VM_SHARED</code> bit is set to 1 for that VMA. Additionally if the file is opened in read only mode, then <code>VM_MAYWRITE</code> is set to 1. This has the effect of making is_cow_mapping return false. Ofcourse, the shared mapping doesn&rsquo;t need to be a COW.</p>

<p>On the other hand, if <code>MAP_PRIVATE</code> is passed in the flags to mmap, then <code>VM_SHARED</code> bit is set to 0, and <code>VM_MAYWRITE</code> remains at 1 (regardless of whether the file is read or write opened, since writes will not be carried to the underlying file). This makes <code>is_cow_mapping</code> return true. Indeed, private mappings should be copy-on-writed.</p>

<p>You can see the code I&rsquo;m talking about <a href="http://lxr.free-electrons.com/source/mm/mmap.c#L1284">conveniently here</a>.</p>

<p>The important point here is that every mapping is either a COW mapping or not a COW mapping. During the clone() system call which is called by <code>fork()</code> library call internally, if the CLONE_VM flag is not passed to <code>clone()</code> as is the case with <code>fork()</code>, then all the VMA mappings of the parent process are copied to the child, including the page table entries. In this case, any writes to COW mappings should trigger a copy on write. The main thing is the children &ldquo;inherit&rdquo; the COW property of all those copied VMA mappings and don&rsquo;t need to be explictly marked as COW.</p>

<p>However, If <code>CLONE_VM</code> is passed, then the VMAs are not copied and the memory descriptor of the child and the parent process are the same, in this case the child and parent share the same address space and are thus are threads. <a href="http://lxr.free-electrons.com/source/kernel/fork.c#L879">See for yourself</a>. COW or no COW doesn&rsquo;t matter here.</p>

<p>So here&rsquo;s a question for you, For N clone() calls with !CLONE_VM for spawning N threads, we can just create as many VMA copies as we want each time, the COW mappings will take care of themselves. Right? Almost! There&rsquo;s more work&hellip; the pages that comprise the source and destination VMA in the copy in question have to marked as read-only. How else will the Copy-on-write of those pages be triggered? Here&rsquo;s the code in <a href="http://lxr.free-electrons.com/source/mm/memory.c#L849">copy_one_pte</a> that sets this up:</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
</pre></td><td class='code'><pre><code class='c'><span class='line'>     <span class="cm">/*</span>
</span><span class='line'><span class="cm">      * If it&#39;s a COW mapping, write protect it both</span>
</span><span class='line'><span class="cm">      * in the parent and the child</span>
</span><span class='line'><span class="cm">      */</span>
</span><span class='line'>     <span class="k">if</span> <span class="p">(</span><span class="n">is_cow_mapping</span><span class="p">(</span><span class="n">vm_flags</span><span class="p">))</span> <span class="p">{</span>
</span><span class='line'>             <span class="n">ptep_set_wrprotect</span><span class="p">(</span><span class="n">src_mm</span><span class="p">,</span> <span class="n">addr</span><span class="p">,</span> <span class="n">src_pte</span><span class="p">);</span>
</span><span class='line'>             <span class="n">pte</span> <span class="o">=</span> <span class="n">pte_wrprotect</span><span class="p">(</span><span class="n">pte</span><span class="p">);</span>
</span><span class='line'>     <span class="p">}</span>
</span></code></pre></td></tr></table></div></figure>


<p>
There you go, now when the COW memory region is written to, a page fault happens, and the page fault handler knows that the VMA of the faulting page is a COW and that&rsquo;s what triggered the page fault. It can then create a copy of the page and restart the faulting instruction, this time removing the write protection if there aren&rsquo;t any others sharing the VMA. So in short, fork+exec can be expensive if you had done lots of <code>fork()</code> on a process with a lot of large files. Since all this copying business is wasted on doing the <code>exec()</code>.</p>

<p>There is one optimization however, why should you have to do this marking for pages that are not physically present in memory? Those will fault anyway. So the above code is <em>not run</em> if the page is not present, nicely done by checking for <a href="http://lxr.free-electrons.com/source/mm/memory.c#L807">!pte_present(pte)</a> to be true before the preceding code.</p>

<p>Please share any comments you may have in the comments section.</p>
</div>
  
  


    </article>
  
  <div class="pagination">
    
    <a href="/blog/archives">Blog Archives</a>
    
  </div>
</div>
<aside class="sidebar">
  
    <section>
  <h1>Recent Posts</h1>
  <ul id="recent_posts">
    
      <li class="post">
        <a href="/blog/2014/04/24/studying-cache-line-sharing-effects-on-smp-systems/">Studying Cache-line Sharing Effects on SMP Systems</a>
      </li>
    
      <li class="post">
        <a href="/blog/2014/04/22/design-of-fork-followed-by-exec-in-linux/">Design of Fork Followed by Exec in Linux</a>
      </li>
    
  </ul>
</section>





  
</aside>

    </div>
  </div>
  <footer role="contentinfo"><p>
  Copyright &copy; 2014 - Joel Fernandes -
  <span class="credit">Powered by <a href="http://octopress.org">Octopress</a></span>
</p>

</footer>
  







  <script type="text/javascript">
    (function(){
      var twitterWidgets = document.createElement('script');
      twitterWidgets.type = 'text/javascript';
      twitterWidgets.async = true;
      twitterWidgets.src = '//platform.twitter.com/widgets.js';
      document.getElementsByTagName('head')[0].appendChild(twitterWidgets);
    })();
  </script>





</body>
</html>
